{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 14\n",
    "\n",
    "Name: Minh Le\n",
    "\n",
    "UID: U18511806\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Naive Bayes\n",
    "- Model Evaluation\n",
    "\n",
    "### Naive Bayes\n",
    "\n",
    "| Attribute A | Attribute B | Attribute C | Class |\n",
    "| ----------- | ----------- | ----------- | ----- |\n",
    "| Yes         | Single      | High        | No    |\n",
    "| No          | Married     | Mid         | No    |\n",
    "| No          | Single      | Low         | No    |\n",
    "| Yes         | Married     | High        | No    |\n",
    "| No          | Divorced    | Mid         | Yes   |\n",
    "| No          | Married     | Low         | No    |\n",
    "| Yes         | Divorced    | High        | No    |\n",
    "| No          | Single      | Mid         | Yes   |\n",
    "| No          | Married     | Low         | No    |\n",
    "| No          | Single      | Mid         | Yes   |\n",
    "\n",
    "a) Compute the following probabilities:\n",
    "\n",
    "- P(Attribute A = Yes | Class = No)\n",
    "- P(Attribute B = Divorced | Class = Yes)\n",
    "- P(Attribute C = High | Class = No)\n",
    "- P(Attribute C = Mid | Class = Yes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- P(Attribute A = Yes | Class = No) = 3/7\n",
    "- P(Attribute B = Divorced | Class = Yes) = 1/3\n",
    "- P(Attribute C = High | Class = No) = 3/7\n",
    "- P(Attribute C = Mid | Class = Yes) = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Classify the following unseen records:\n",
    "\n",
    "- (Yes, Married, Mid)\n",
    "- (No, Divorced, High)\n",
    "- (No, Single, High)\n",
    "- (No, Divorced, Low)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (Yes, Married, Mid) --> No\n",
    "- (No, Divorced, High) --> No\n",
    "- (No, Single, High) --> No\n",
    "- (No, Divorced, Low) --> No\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "a) Write a function to generate the confusion matrix for a list of actual classes and a list of predicted classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "actual_class = [\"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No\"]\n",
    "predicted_class = [\"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\"]\n",
    "\n",
    "\n",
    "def confusion_matrix(actual, predicted):\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == \"Yes\" and predicted[i] == \"Yes\":\n",
    "            tp += 1\n",
    "        elif actual[i] == \"No\" and predicted[i] == \"No\":\n",
    "            tn += 1\n",
    "        elif actual[i] == \"No\" and predicted[i] == \"Yes\":\n",
    "            fp += 1\n",
    "        elif actual[i] == \"Yes\" and predicted[i] == \"No\":\n",
    "            fn += 1\n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "\n",
    "print(confusion_matrix(actual_class, predicted_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Assume you have the following Cost Matrix:\n",
    "\n",
    "|            | predicted = Y | predicted = N |\n",
    "| ---------- | ------------- | ------------- |\n",
    "| actual = Y | -1            | 5             |\n",
    "| actual = N | 10            | 0             |\n",
    "\n",
    "What is the cost of the above classification?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we have this Confusion Matrix:\n",
    "\n",
    "|            | predicted = Y | predicted = N |\n",
    "| ---------- | ------------- | ------------- |\n",
    "| actual = Y | 2             | 1             |\n",
    "| actual = N | 3             | 4             |\n",
    "\n",
    "$-1 * 2 + 5 * 1 + 10 * 3 + 0 * 4 = 33$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Write a function that takes in the actual values, the predictions, and a cost matrix and outputs a cost. Test it on the above example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 33\n"
     ]
    }
   ],
   "source": [
    "def compute_classification_cost(actual, predicted, cost_matrix):\n",
    "    assert len(actual) == len(\n",
    "        predicted\n",
    "    ), \"Actuals and predictions should have the same length.\"\n",
    "    tp, tn, fp, fn = confusion_matrix(actual, predicted)\n",
    "\n",
    "    cost = (\n",
    "        tp * cost_matrix[\"YY\"]\n",
    "        + tn * cost_matrix[\"NN\"]\n",
    "        + fp * cost_matrix[\"NY\"]\n",
    "        + fn * cost_matrix[\"YN\"]\n",
    "    )\n",
    "\n",
    "    return cost\n",
    "\n",
    "\n",
    "cost_matrix = {\"YY\": -1, \"YN\": 5, \"NY\": 10, \"NN\": 0}\n",
    "\n",
    "cost = compute_classification_cost(actual_class, predicted_class, cost_matrix)\n",
    "print(f\"Cost: {cost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Implement functions for the following:\n",
    "\n",
    "- accuracy\n",
    "- precision\n",
    "- recall\n",
    "- f-measure\n",
    "\n",
    "and apply them to the above example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.60\n",
      "Precision: 0.40\n",
      "Recall: 0.67\n",
      "F-measure: 0.50\n"
     ]
    }
   ],
   "source": [
    "def accuracy(actuals, predictions):\n",
    "    correct = sum(a == p for a, p in zip(actuals, predictions))\n",
    "    return correct / len(actuals)\n",
    "\n",
    "\n",
    "def precision(actuals, predictions):\n",
    "    true_positive = sum(a == \"Yes\" and p == \"Yes\" for a, p in zip(actuals, predictions))\n",
    "    predicted_positive = sum(p == \"Yes\" for p in predictions)\n",
    "    return true_positive / predicted_positive if predicted_positive != 0 else -1\n",
    "\n",
    "\n",
    "def recall(actuals, predictions):\n",
    "    true_positive = sum(a == \"Yes\" and p == \"Yes\" for a, p in zip(actuals, predictions))\n",
    "    actual_positive = sum(a == \"Yes\" for a in actuals)\n",
    "    return true_positive / actual_positive if actual_positive != 0 else 0\n",
    "\n",
    "\n",
    "def f_measure(actuals, predictions):\n",
    "    p = precision(actuals, predictions)\n",
    "    r = recall(actuals, predictions)\n",
    "    return 2 * p * r / (p + r) if p + r != 0 else 0\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy(actual_class, predicted_class):.2f}\")\n",
    "print(f\"Precision: {precision(actual_class, predicted_class):.2f}\")\n",
    "print(f\"Recall: {recall(actual_class, predicted_class):.2f}\")\n",
    "print(f\"F-measure: {f_measure(actual_class, predicted_class):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
